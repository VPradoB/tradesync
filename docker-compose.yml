services:
  # TODO: sometimes got errors connecting to kafka because kafka is not ready.
  # TODO: standarize containers names and titles.
  writer-api:
    build:
      context: ./src/writer_api
    container_name: writer-api
    ports:
      - "5001:8000"
    networks:
      - backend
    env_file:
      - ./src/writer_api/.env
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_started
  reader-api:
    build: ./src/reader_api
    container_name: reader-api 
    ports:
      - "5002:8000"
    networks:
      - backend
    depends_on:
      - kafka
      - mongodb
  nginx:
    image: nginx:latest
    container_name: nginx
    volumes:
      - ./src/nginx/nginx.conf:/etc/nginx/conf.d/default.conf
    ports:
      - "8000:80"
    depends_on:
      - writer-api
      - reader-api
    networks:
      - backend
  stripe-listener:
    image: stripe/stripe-cli
    container_name: stripe-listener
    entrypoint: sh -c "stripe listen --forward-to http://host.docker.internal:5001/webhook | tee /whsec.txt"
    env_file:
      - src/simulator/.env
    networks:
      - backend
    extra_hosts:
      - "host.docker.internal:host-gateway"
  mongodb:
     image: mongo:latest
     container_name: event-source
     restart: always
     ports: 
       - "27017:27017"
     environment:
       MONGO_INITDB_ROOT_USERNAME: root
       MONGO_INITDB_ROOT_PASSWORD: example
     networks:
       - backend
     volumes: 
       - event_source_data:/data/db
     healthcheck:
       test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
       interval: 10s
       timeout: 5s
       retries: 5
       start_period: 30s
  reader-database:
    image: postgres:latest
    container_name: reader-database
    restart: always
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: mydb
    networks:
      - backend
    volumes:
      - reader_db_data:/var/lib/postgresql/data
  redis:
    image: redis:latest
    container_name: reader-db-cache-server
    restart: always
    ports:
      - "6379:6379"
    networks:
      - backend
    volumes:
      - cache_server_data:/data
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
     - backend
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    restart: always
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "stripe-events:1:1"
    ports:
      - "9092:9092"
      - "29092:29092"
    networks:
      - backend
# just using one network for simplicity.
networks:
  backend:

volumes:
  reader_db_data:
  event_source_data:
  cache_server_data:
